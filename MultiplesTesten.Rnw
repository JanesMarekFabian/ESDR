%-------------------------------------------------------------------------------
\chapter{Multiples Testen}\label{Chap.multtest}
%-------------------------------------------------------------------------------
In diesem Kapitel wird das Problem des multiplen Testens besprochen. Im einzelnen
geht es um folgende Themen:
\begin{itemize}
\item Family-wise error rate (FWER)
\item False discovery rate (FDR)
\end{itemize}
\noindent
Der R Code für dieses Kapitel ist in der Datei \texttt{MultiplesTesten.Rmd} enthalten,
welche Sie von meinem GitHub-Account herunterladen können 
(Link: \url{https://github.com/stamats/ESDR/blob/master/MultiplesTesten.Rmd}). 
Klicken Sie mit der rechten Maustaste auf \texttt{Raw}. Dann können Sie 
das \texttt{Ziel speichern unter...}. Am wenigsten Schwierigkeiten ergeben sich, 
wenn Sie meine R Markdown Dateien im selben Ordner wie die Daten, welche in den 
jeweiligen Kapiteln verwendet werden, speichern.\\
Wir installieren zunächst die in diesem Kapitel benötigten Pakete.
<<eval=FALSE>>=
BiocManager::install("multtest", update = FALSE)
BiocManager::install("limma", update = FALSE)
install.packages("MKomics")
@
Achten Sie darauf, dass Sie die Pakete der vorhergehenden 
Kapitel~\ref{Chap.Desk}--\ref{Chap.Test} bereits installiert haben. Wir laden 
alle Pakete.
<<message=FALSE>>=
library(DescTools)
library(ggplot2)
library(MKdescr)
library(RColorBrewer)
library(ggsci)
library(distr)
library(distr6)
library(distrMod)
library(qqplotr)
library(RobLox)
library(MKinfer)
library(ROptEst)
library(RobExtremes)
library(MKpower)
library(RVAideMemoire)
library(coin)
library(exactRankTests)
library(ggpubr)
library(datarium)
library(gridExtra)
library(NSM3)
library(multtest)
library(MKomics)
@
Wie bereits in Abschnitt~\ref{Sec.Installation} erklärt, ist ein wiederholtes
Ausführen von \code{library} unproblematisch.
%-------------------------------------------------------------------------------
\section{Einführung}
%-------------------------------------------------------------------------------
Im Kapitel~\ref{Chap.Test} haben wir schon einige der Fallstricke beim statistischen
Testen kennengelernt. Dort war jedoch die Annahme, dass man lediglich einen 
statistischen Test durchführt und das Ergebnis dieses Testes den Erfolg oder 
Mißerfolg einer Studie beschreibt. Dies ist in der Praxis immer noch oft der 
Fall. Im Kontext von klinischen Studien spricht man etwa vom 
\textbf{primären Endpunkt}, der immer noch häufig durch einen einzigen Parameter 
beschrieben wird. Es häufen sich jedoch auch die Situationen, in denen dies nicht
mehr als adäquat angesehen wird. Zum Beispiel sollten im Fall von Migräne vier
Parameter herangezogen werden: Schmerz, Übelkeit, Lichtempfindlichkeit und 
Geräuschempfindlichkeit (\citet{Offen2007}). Entsprechend werden in immer mehr
Studien nicht nur eine, sondern mehrere (primäre) Hypothesen gleichzeitig 
untersucht.\\

\noindent
Außerdem wurden in den letzten Jahren und Jahrzehnten etwa in der Biologie und 
Medizin Hochdurchsatzverfahren entwickelt, mit denen es möglich ist, hunderte 
oder tausende von Parametern (z.B.\ Gene, Proteine oder Metaboliten) simultan zu 
messen. Auch im Internet oder von Smartphone-Apps werden eine Vielzahl von 
Variablen gleichzeitig ermittelt und deren Relevanz z.B.\ für die Platzierung
von Werbeanzeigen oder das Einkaufsverhalten untersucht. Man spricht in diesem
Zusammenhang heute auch von \textbf{``big data''}, die dann von einem 
Bioinformatiker oder ``data scientist'' ausgewertet und visualisert werden.\\

\noindent
In immer mehr Bereichen werden demnach nicht nur eine, sondern $N > 1$ Hypothesen
gleichzeitig betrachtet und entsprechend müssen nicht nur ein, sondern $N$ 
statistische Tests simultan durchgeführt werden. Wir wissen:
\begin{itemize}
\item für einen einzelnen Test haben wir einen Fehler 1.\ Art von $\alpha\in(0,1)$
\item Falls wir $N > 1$ Hypothesen testen und zwar jeweils zum gleichen 
Signifikanzniveau $\alpha$, haben wir für jeden einzelnen der $N$ Tests wieder 
einen Fehler 1.\ Art von $\alpha$.
\end{itemize}
Wir wissen jedoch nicht, wie groß die Fehlerwahrscheinlichkeit für alle $N$ 
Tests zusammen ist bzw.\ viel grundlegender, wie sich der Fehler 1.\ Art am 
besten auf $N$ Tests übertragen lässt. Im Folgenden wollen wir uns mit zwei 
Ansätzen befassen, welche das Konzept des Fehlers 1.\ Art auf $N > 1$ Tests 
übertragen.
%-------------------------------------------------------------------------------
\section{Family-wise Error Rate (FWER)}
%-------------------------------------------------------------------------------
Im Fall der \textbf{family-wise error rate (FWER)} betrachtet man die 
Wahrscheinlichkeit bei $N\in\N$ Tests mindestens einen Fehler 1.\ Art
zu machen; d.h.,
\begin{equation}
  \mbox{FWER} = P(\mbox{``mind.\ $1$ Fehler 1.\ Art''})
\end{equation}
Die exakte Berechnung dieser Wahrscheinlichkeit ist generell schwierig. Im Fall, 
dass die $N$ Hypothesen (stochastisch) unabhängig voneinander sind und alle 
$N$ statistischen Tests mit dem gleichen Signifikanzniveau $\alpha\in(0,1)$ 
durchgeführt werden, ist die exakte Berechnung aber möglich. Wir benutzen 
zunächst die Gegenwahrscheinlichkeit
\begin{equation}
  \mbox{FWER} = P(\mbox{``mind.\ $1$ Fehler 1.\ Art''}) = 
  1 - P(\mbox{``kein Fehler 1.\ Art''})
\end{equation}
wobei im Fall eines einzelnen Tests gilt 
\begin{equation}
  N = 1:\qquad P(\mbox{``kein Fehler 1.\ Art''}) = \mbox{Sensitivität} = 1 - \alpha
\end{equation}
Im Fall von $N$ (stochastisch) unabhängigen Tests folgt
\begin{equation}
  P(\mbox{``kein Fehler 1.\ Art''}) = (1 - \alpha)^N
\end{equation}
Damit ergibt sich
\begin{equation}
  \mbox{FWER} = 1 - (1-\alpha)^N
\end{equation}
Wir stellen die Situation für $\alpha = 0.05$ grafisch dar.
<<FWER>>=
N <- 1:150
FWER <- 100*(1 - (1-0.05)^N)
DF <- data.frame(N = N, FWER = FWER)
ggplot(DF, aes(x = N, y = FWER)) + 
  geom_point() + geom_line() + xlab("Anzahl an Tests") + ylab("FWER [%]") + 
  ggtitle("FWER unter der Annahme von unabhängigen Tests")
@
Die FWER steigt demnach recht schnell mit der Anzahl der Tests an und wir 
erhalten zum Beispiel
<<>>=
round(DF[c(1,2,3,5,10,14,45,59,90),], 1)
@
Leider ist die Annahme unabhängiger Hypothesen und Tests in der Praxis in den
allermeisten Fällen nicht erfüllt. Hinzu kommt, dass die genaue Abhängigkeitstruktur 
zwischen den Hypothesen in der Praxis schwer zu beschreiben bzw.\ nicht bekannt 
ist. Damit ist die exakte Berechnung der FWER üblicher Weise nicht 
möglich und man kann sich nur Abschätzungen (durch obere Schranken) bedienen.\\
Die einfachste und auch allgemein gültigste Abschätzung folgt direkt aus der
Eigenschaft der sogenannten Sub-Additivität von Wahrscheinlichkeitsmaßen
\begin{equation}
  P\left(\bigcup_{i=1}^N A_i\right) \le \sum_{i=1}^N P(A_i)
\end{equation}
für beliebige (messbare) Ereignisse $A_1, \ldots, A_N$. Hieraus ergibt sich mit
\begin{equation}
  P(A_i) = \mbox{``Fehler 1.\ Art von Test $i$''} = \alpha \qquad \forall i=1,\dots,N
\end{equation}
die folgende Abschätzung für die FWER
\begin{equation}
  \mbox{FWER} \le \min\{N\alpha,\, 1\}
\end{equation}
Da $N\alpha > 1$ für $N > \frac{1}{\alpha}$, wird das Minimum aus $N\alpha$ und 
$1$ gebildet, um in jedem Fall eine gültige Wahrscheinlichkeit ($\in[0,1]$) 
zu erhalten. Verwenden wir anstelle von $\alpha$ ein kleineres Signifikanzniveau 
$\tilde\alpha < \alpha$ für jeden Test, speziell $\tilde\alpha = \frac{\alpha}{N}$,
so erhalten wir
\begin{equation}
  \mbox{FWER} \le \min\{N\tilde\alpha,\, 1\} = N\tilde\alpha 
  = N\frac{\alpha}{N} = \alpha
\end{equation}
Offensichtlich lässt sich diese Abschätzung auch auf die p~Werte $p_1,\ldots,p_n$ 
der Tests übertragen und es ist äquivalent die p~Werte analog zu verkleinern. 
Anstelle $p_i$ mit $\tilde\alpha$ zu vergleichen, vergleicht man 
$\tilde p_i = \min\{N p_i,\,1\}$ mit $\alpha$.
\begin{Kommentar}\noindent
Anmerkung:\\
In der Praxis werden beim multiplen Testen üblicherweise die p~Werte adjustiert.
Die einzige wichtige Ausnahme bildet die Fallzahlplanung. Hier ist es in der 
Regel einfacher, mit der Adjustierung des Signifikanzniveaus zu arbeiten.
\end{Kommentar}
\noindent
Der oben skizzierte Ansatz ist als \textbf{Bonferroni-Methode} bekannt.
%-------------------------------------------------------------------------------
\begin{Algo}
Gegeben seien $N\in\N$ statistische Tests zum Signifikanzniveau $\alpha\in(0,1)$ 
mit Nullhypothesen $H_{0,1},\ldots,H_{0,N}$ und entsprechenden Alternativen 
$H_{1,1},\ldots,H_{1,N}$, welche zu den $p$ Werten $p_1,\ldots,p_N$ führen. 
Die \textbf{Bonferroni-Methode} ist das folgende ein-Schritt Verfahren:
\begin{enumerate}
\item Ersetze $p_i$ durch $\tilde p_i := \min\{N p_i, 1\}$ ($\forall i = 1,\ldots,N$).
\item Falls $\tilde p_i \le\alpha$, wähle $H_{1,i}$, andernfalls behalte 
$H_{0,i}$ bei ($\forall i = 1,\ldots,N$).
\end{enumerate}
\end{Algo}
\begin{Kommentar}\noindent
Anmerkung:\\
Die Methode von Bonferroni benötigt keine Kenntnis über die Abhängigkeitsstruktur 
der Hypothesen. Dies führt dazu, dass die Bonferroni-Methode sehr konservativ ist; 
d.h., man hat eine hohe Sicherheit, dass man keine falsch positiven Entscheidungen 
trifft. Jedoch werden dadurch umgekehrt auch viele korrekterweise positive Tests 
als nicht signifikant eingestuft. Die Power dieser Methode ist demnach 
vergleichsweise klein bzw.\ der Fehler 2.\ Art vergleichsweise groß. 
\end{Kommentar}
\noindent
Es gibt neben der Bonferroni-Methode etwas weniger konservative sogenannte 
mehr-Schritt Verfahren, um die FWER zu kontrollieren. Für diese Verfahren müssen 
die p~Werte in einem ersten Schritt zunächst aufsteigend sortiert werden
$$
  p_{(1)}\le p_{(2)}\le\ldots\le p_{(N)}
$$
Die wichtigste Alternative zur Bonferroni-Methode ist die Methode von \citet{Holm1979}, 
die auch als \textbf{Bonferroni-Holm-Methode} bekannt ist.
%-------------------------------------------------------------------------------
\begin{Algo}
Gegeben seien $N\in\N$ statistische Tests zum Signifikanzniveau $\alpha\in(0,1)$ 
mit Nullhypothesen $H_{0,1},\ldots,H_{0,N}$ und entsprechenden Alternativen 
$H_{1,1},\ldots,H_{1,N}$, welche zu den $p$ Werten $p_1,\ldots,p_N$ führen. 
Weiter seien $p_{(1)}, \ldots, p_{(N)}$ die aufsteigend sortierten $p$ Werte 
und $H_{0,(j)}$ und $H_{1,(j)}$ ($j = 1,\ldots,N$) die zugehörigen Hypothesen. 
Die \textbf{Bonferroni-Holm-Methode} besteht für $j=1,\ldots,N$ aus den folgenden 
beiden Schritten:
\begin{enumerate}
\item Ersetze $p_{(j)}$ durch
\begin{equation}\label{eq.Holm}
 \tilde p_{(j)} = \max\limits_{k=1,\ldots,j}\left\{\min\big\{(N-k+1)p_{(k)}, 1\big\}\right\}
\end{equation}
\item Falls $\tilde p_{(j)} \le\alpha$, wähle $H_{1,(j)}$, andernfalls behalte 
$H_{0,(j)}$ bei.
\end{enumerate}
\end{Algo}
\begin{Kommentar}\noindent
Anmerkung:\\
Die Bonferroni-Holm-Methode ist ein sogenanntes \textbf{step-down Verfahren}; 
d.h., ausgehend vom kleinsten p~Wert werden Schritt für Schritt größere p~Werte 
hinzugenommen. Dieses Verfahren ist etwas weniger konservativ (d.h., hat größere 
Power) als die Bonferroni Methode.
\end{Kommentar}
\noindent
Wir betrachten ein einfaches Beispiel.
\begin{Exa}\label{Exa2}
Gegeben seien $6$ Tests zu einem Signifikanzniveau von $5\%$ mit Nullhypothesen 
$H_{0,1},\ldots,H_{0,6}$ und Alternativen $H_{1,1},\ldots,H_{1,6}$. Die 
zugehörigen p~Werte seien
$$
  p_1 = 0.004,\;p_2 = 0.011,\; p_3 = 0.039,\; p_4 = 0.012,\; p_5 = 0.001,\; p_6 = 0.480
$$
Ohne eine Adjustierung der p~Werte würde man sich demnach bei einem Signifikanzniveau
von $5\%$ in fünf der sechs Fälle für die Alternative entscheiden.
\par\textbf{(a)} Die Bonferroni-Methode ergibt
\begin{align*}
  \tilde p_1 &= 6 p_1 = \textbf{0.024}\\
  \tilde p_2 &= 6 p_2 = 0.066\\
  \tilde p_3 &= 6 p_3 = 0.234\\
  \tilde p_4 &= 6 p_4 = 0.072\\
  \tilde p_5 &= 6 p_5 = \textbf{0.006}\\
  \tilde p_6 &= 6 p_6 = 2.880 \Longrightarrow 1.000
\end{align*}
Wir gleichen unsere Ergebnisse mit den Ergebnissen der Funktion \code{p.adjust} 
ab.
<<Bonferroni>>=
pval <- c(0.004, 0.011, 0.039, 0.012, 0.001, 0.480)
p.adjust(pval, method = "bonferroni")
@
\noindent
d.h., ``nur'' $H_{0,1}$ und $H_{0,5}$ können zum $5\%$ Niveau abgelehnt werden.
\par\textbf{(b)} Wir stellen zunächst fest
$$
  p_5 \le p_1 \le p_2 \le p_4 \le p_3 \le p_6
$$
Wir berechnen basierend auf dieser Reihenfolge die adjustierten p~Werte 
mit Hilfe der Bonferroni-Holm-Methode
\begin{align*}
  \tilde p_5 &= 6 p_5 = \textbf{0.006}\\
  \tilde p_1 &= 5 p_1 = \textbf{0.020}\\
  \tilde p_2 &= 4 p_2 = \textbf{0.044}\\
  \tilde p_4 &= 3 p_4 = 0.036\Longrightarrow \textbf{0.044}\\
  \tilde p_3 &= 2 p_3 = 0.078\\
  \tilde p_6 &= 1 p_6 = 0.480
\end{align*}
Im Fall von $\tilde p_4$ läge der berechnete Wert von $0.036$ unter dem 
vorherigen Wert von $\tilde p_2$. Dies ist nicht zulässig und wird durch die 
Maximumbildung in der Gleichung~(\ref{eq.Holm}) verhindert.
Wir kontrollieren die Ergebnisse wieder mit Hilfe der Funktion \code{p.adjust},
wobei eine Sortierung der p~Werte nicht nötig ist, sondern innerhalb der 
Funktion vorgenommen wird.
<<Holm>>=
## Sortierung nicht nötig
p.adjust(pval, method = "holm")
@
\noindent
Damit können wir die Nullhypothesen $H_{0,5}$, $H_{0,1}$, $H_{0,2}$ und 
$H_{0,4}$ zum $5\%$ Niveau ablehnen. Dies zeigt insbesondere, dass die 
Bonferroni-Holm-Methode weniger konservativ ist als die Bonferroni-Methode.
\end{Exa}
\noindent
Eine weiteres bekanntes Adjustierungsverfahren ist die Simes-Hochberg-Methode.
\begin{Algo}
Gegeben seien $N\in\N$ \textbf{unabhängige} statistische Tests zum Signifikanzniveau 
$\alpha\in(0,1)$ mit Nullhypothesen $H_{0,1},\ldots,H_{0,N}$ und entsprechenden 
Alternativen $H_{1,1},\ldots,H_{1,N}$, welche zu den $p$ Werten $p_1,\ldots,p_N$ 
führen. Weiter seien $p_{(1)}, \ldots, p_{(N)}$ die aufsteigend sortierten $p$~Werte 
und $H_{0,(j)}$ und $H_{1,(j)}$ ($j = 1,\ldots,N$) die zugehörigen Hypothesen. 
Die \textbf{Simes-Hochberg-Methode} besteht für $j=1,\ldots,N$ aus den folgenden 
beiden Schritten:
\begin{enumerate}
\item Ersetze $p_{(j)}$ durch
\begin{equation}
 \tilde p_{(j)} = \min\limits_{k=j,\ldots,N}\left\{\min\{(N-k+1)p_{(k)}, 1\}\right\}
\end{equation}
\item Falls $\tilde p_{(j)} \le\alpha$, wähle $H_{1,(j)}$, andernfalls behalte 
$H_{0,(j)}$ bei.
\end{enumerate}
\end{Algo}
\begin{Kommentar}\noindent
Anmerkung:\\
Die Simes-Hochberg Method ist ein sogenanntes \textbf{step-up Verfahren}; d.h., 
man startet mit allen p~Werten und lässt sukzessive den kleinsten weg. Dieses 
Verfahren ist etwas weniger konservativ als die Bonferroni-Holm Methode, benötigt 
aber zusätzlich unabhängige Tests, was eine recht starke Voraussetzung darstellt 
und in der Praxis meist nicht zutrifft. Daher wird in der Praxis in den meisten 
Fällen die Bonferroni-Holm Methode zur Kontrolle der FWER eingesetzt.
\end{Kommentar}
\noindent
Wir betrachten im folgenden Beispiel die Situation von Beispiel~\ref{Exa2}.
\begin{Exa}
Wir nehmen zusätzlich an, dass die Tests unabhängig sind. Wir berechnen mit
Hilfe des Simes-Hochberg Verfahrens die adjustierten p~Werte, wobei zur
Erinnerung
$$
  p_5 \le p_1 \le p_2 \le p_4 \le p_3 \le p_6
$$
Wir erhalten
\begin{align*}
  \tilde p_5 &= \min \{6 p_5, 5 p_1, 4 p_2, 3 p_4, 2 p_3, 1 p_6\} = 6 p_5 = \textbf{0.006}\\
  \tilde p_1 &= \min \{5 p_1, 4 p_2, 3 p_4, 2 p_3, 1 p_6\} = 5 p_1 = \textbf{0.020}\\
  \tilde p_2 &= \min \{4 p_2, 3 p_4, 2 p_3, 1 p_6\} = 3 p_4 = \textbf{0.036}\\
  \tilde p_4 &= \min \{3 p_4, 2 p_3, 1 p_6\} = 3 p_4 = \textbf{0.036}\\
  \tilde p_3 &= \min \{2 p_3, 1 p_6\} = 2 p_3 = 0.078\\
  \tilde p_6 &= 1 p_6 = 0.480
\end{align*}
Wir kontrollieren unsere Berechnungen wieder mit Hilfe der Funktion \code{p.adjust}.
<<Hochberg>>=
## Sortieren nicht nötig
p.adjust(pval, method = "hochberg")
@
\noindent
Damit können wir wie im Fall der Bonferroni-Holm-Methode die Nullhypothesen 
$H_{0,5}$, $H_{0,1}$, $H_{0,2}$ und $H_{0,4}$ zum $5\%$ Niveau ablehnen, 
wobei aber $\tilde p_2$ und $\tilde p_4$ etwas kleiner sind als im Fall von 
Bonferroni-Holm. Dies zeigt insbesondere, dass das Simes-Hochberg-Verfahren 
etwas weniger konservativ ist als die Bonferroni-Holm-Methode. Jedoch wird dies 
durch die zusätzliche Voraussetzung von unabhängigen Tests recht teuer erkauft.
\end{Exa}
\begin{Kommentar}\noindent
Anmerkung:\\
In der Praxis ist es in den meisten Fällen empfehlenswert, das 
Bonferroni-Holm-Verfahren für die Adjustierung von p~Werten anzuwenden, um
die FWER zuverlässig zu kontrollieren.
\end{Kommentar}
\noindent
Abschließend betrachten wir noch ein Beispiel zur Fallzahlplanung in einer
Situation mit multiplen primären Endpunkten.
\begin{Exa}
Wir nehmen an, dass wir drei (primäre) Endpunkte simultan betrachten wollen, 
wobei zwei Gruppen miteinander verglichen werden sollen. Die Studie ist demnach
nur dann erfolgreich, wenn wir für alle drei Endpunkte einen signifikanten 
Unterschied erhalten. Zur Vereinfachung nehmen wir weiter an, dass die drei 
Parameter, welche die primären Endpunkte widerspiegeln, einer Normalverteilung 
folgen. Die Gruppen können hierbei jeweils unterschiedliche Standardabweichungen 
aufweisen. Folglich entscheiden wir uns für den Welch t-Test für die 
Fallzahlplanung. Wir erwarten für die drei Endpunkte die folgenden Situationen:
\begin{description}
\item[Endpunkt 1:] $|\mu_1 - \mu_2| = 0.5$, $\sigma_1 = 1$, $\sigma_2 = 1.2$
\item[Endpunkt 2:] $|\mu_1 - \mu_2| = 0.75$, $\sigma_1 = 1.5$, $\sigma_2 = 1.2$
\item[Endpunkt 3:] $|\mu_1 - \mu_2| = 1.0$, $\sigma_1 = 1.5$, $\sigma_2 = 1.75$
\end{description}
Wir wollen in der Studie eine Power von mindestens $90\%$ erreichen. Außerdem 
soll die FWER maximal $5\%$ betragen. Für die Fallzahlplanung ist es in solchen
Fällen meist am einfachsten die Bonferroni-Methode heranzuziehen. Wir sollten 
demnach die Tests mit einem Fehler 1.\ Art von $\alpha = 0.05/3$ durchführen. 
Es ergibt sich
<<>>=
## Endpunkt 1
power.welch.t.test(delta = 0.5, sd1 = 1.0, sd2 = 1.2, 
                   sig.level = 0.05/3, power = 0.9)
## Endpunkt 2
power.welch.t.test(delta = 0.75, sd1 = 1.5, sd2 = 1.2, 
                   sig.level = 0.05/3, power = 0.9)
## Endpunkt 3
power.welch.t.test(delta = 1.0, sd1 = 1.5, sd2 = 1.75, 
                   sig.level = 0.05/3, power = 0.9)
@
Wir erhalten für den ersten Endpunkt die höchste Fallzahl. Die Studie sollte 
folglich mit einer Fallzahl von 134 Probanden pro Gruppe durchgeführt werden,
um die gewünschte Power von mindestens $90\%$ zu erreichen und eine FWER 
von maximal $5\%$ einzuhalten.
<<>>=
## Endpunkt 2
power.welch.t.test(delta = 0.75, sd1 = 1.5, sd2 = 1.2, 
                   sig.level = 0.05/3, n = 134)
## Endpunkt 3
power.welch.t.test(delta = 1.0, sd1 = 1.5, sd2 = 1.75, 
                   sig.level = 0.05/3, n = 134)
@
Im Fall von Endpunkt 2 und 3 führt eine Fallzahl von 134 Probanden pro Gruppe 
demnach auf eine Power von $98.2\%$ und $99.5\%$. Diese Herangehensweise 
ignoriert einen möglichen Zusammenhang zwischen den Variablen. Falls auch die 
Korrelationen zwischen den Variablen bekannt sind, könnte auch unter Verwendung 
von multivariaten Normalverteilungen eine Fallzahlberechnung durchgeführt werden
zum Beispiel mit Hilfe von Monte-Carlo Simulationen.
\end{Exa}
\begin{Kommentar}\noindent
Anmerkung:\\
Es besteht das generelle Problem, dass alle bekannten Ansätze die FWER zu 
kontrollieren, recht konservativ sind, indem sie eine recht starke Adjustierung 
der $p$ Werte enthalten. Daher führen diese Verfahren gerade in Situationen mit 
vielen Tests ($> 10$) dazu, dass viele wahre Unterschiede unentdeckt bleiben. 
\end{Kommentar}
\noindent
%-------------------------------------------------------------------------------
\section{False Discovery Rate (FDR)}
%-------------------------------------------------------------------------------
Die Konservativität der FWER bzw.\ der bekannten FWER-Verfahren hat dazu geführt, 
dass man für Situationen mit vielen oder sehr vielen parallelen Tests nach 
Alternativen gesucht hat. Wir betrachten hierzu zunächst die möglichen 
\textbf{Testentscheidungen beim multiplen Testen}.\\
\begin{table}[!ht]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{Entscheidung für} & \\
 i = 1,\ldots,N & für $\textrm{H}_{0i}$ & gegen $\textrm{H}_{0i}$ & Summe \\ \hline
 $\textrm{H}_{0i}$ richtig & $U$ & $V$ & $N_0 (= U+V)$ \\ \hline
 $\textrm{H}_{0i}$ falsch & $W$ & $S$ & $N_1 (=W+S)$ \\ \hline
 Summe & $N-R (=U+W)$ & $R (=V+S)$ & $N (=U+V+W+S)$ \\ \hline
\end{tabular} 
\caption{Testentscheidungen beim multiplen Testen.}\label{Tab.multTests}
\end{center}
\end{table}

\noindent
Offenbar gilt mit diesen Bezeichungen: $\textrm{FWER} = P(V \ge 1)$. Es bietet
sich an, anstelle der strikten Kontrolle der Wahrscheinlichkeit von falsch 
positiven Testergebnissen nach einer Kontrolle ``im Mittel'' (d.h.\ im Erwartungswert) 
zu suchen. Dies führte zum erwarteten Anteil falsch positiver Tests an allen 
positiven Tests, was als \textbf{false discovery rate (FDR)} bezeichnet wird
\begin{equation}
 \textrm{FDR} = \Ew\left(\frac{V}{R}\right) = \Ew\left(\frac{V}{V + S}\right)
\end{equation}
Allgemein gilt: FDR $\le$ FWER, was bedeutet, dass die FDR weniger konservativ
als die FWER ist. Das wohl am häufigsten verwendete Verfahren zur Berechnung der 
FDR adjustierten p~Werte ist die Methode von \citet{Benjamini1995}.
\begin{Algo}
Gegeben seien $N\in\N$ \textbf{unabhängige} bzw.\ \textbf{positiv abhängige} statistische 
Tests zum Signifikanzniveau $\alpha\in(0,1)$ mit Nullhypothesen $H_{0,1},\ldots,H_{0,N}$ 
und entsprechenden Alternativen $H_{1,1},\ldots,H_{1,N}$, welche zu den p~Werten 
$p_1,\ldots,p_N$ führen. Weiter seien $p_{(1)}, \ldots, p_{(N)}$ die aufsteigend 
sortierten p~Werte und $H_{0,(j)}$ und $H_{1,(j)}$ ($j = 1,\ldots,N$) die 
zugehörigen Hypothesen. Die \textbf{Benjamini-Hochberg-Methode} besteht für 
$j=1,\ldots,N$ aus den folgenden beiden Schritten:
\begin{enumerate}
\item Ersetze $p_{(j)}$ durch
\begin{equation}
 \tilde p_{(j)} = \min\limits_{k=j,\ldots,N}\left\{\min\left\{\frac{N}{k}p_{(k)}, 1\right\}\right\}
\end{equation}
\item Falls $\tilde p_{(j)} \le\alpha$, wähle $H_{1,(j)}$, andernfalls behalte 
$H_{0,(j)}$ bei.
\end{enumerate}
\end{Algo}
%-------------------------------------------------------------------------------
\begin{Rem}
\par\textbf{(a)}
Die genaue Definition der erlaubten positiven Abhängigkeit ist in \citet{Benjamini2001} 
beschrieben und erfasst, wie dort dargestellt, viele praktische Fragestellungen.
\par\textbf{(b)}
Die Benjamini-Hochberg Methode ist ein \textbf{step-up Verfahren} wie auch die
Methode von Simes-Hochberg. Wir können diese beiden Verfahren auch direkt miteinander
vergleichen, da sie sich nur im Korrekturfaktor unterscheiden. Im Folgenden wollen
wir untersuchen, ob die Benjamini-Hochberg-Methode tatsächlich zu kleinern p~Werten
führt
\begin{align*}
  \frac{N}{k}p_{(k)} &\le (N-k+1)p_{(k)}\qquad\mbox{für }k=1,\ldots,N\\
  \frac{N}{k} &\le (N-k+1)\qquad(p_{(k)} > 0)\\
  N &\le Nk - k^2 + k\\
  0 &\le N(k-1) - k^2 + k\\
  0 &\le N(k-1) - k(k-1)\\
  0 &\le (N-k)(k-1)
\end{align*}
In der letzten Gleichung ist die rechte Seite mit Ausnahme der Fälle $k=1$ und $k = N$ 
immer größer als~$0$; d.h., die adjustierten p~Werte sind im Fall von 
Benjamini-Hochberg in allen Schritten außer dem ersten und den letzten (dort sind 
sie gleich) kleiner als bei Simes-Hochberg.
\end{Rem}
\noindent
Wir setzen Beispiel~\ref{Exa2} fort.
\begin{Exa}
Wir nehmen zusätzlich an, dass die Test unabhängig oder zumindest nur positiv 
abhängig sind. Zur Erinnerung
$$
  p_1 = 0.004,\;p_2 = 0.011,\; p_3 = 0.039,\; p_4 = 0.012,\; p_5 = 0.001,\; p_6 = 0.480
$$
und
$$
  p_5 \le p_1 \le p_2 \le p_4 \le p_3 \le p_6
$$
Wir erhalten mit dem Benjamini-Hochberg-Verfahren
\begin{align*}
  \tilde p_5 &= \min \left\{\frac{6}{1} p_5, \frac{6}{2} p_1, \frac{6}{3} p_2, 
  \frac{6}{4} p_4, \frac{6}{5} p_3, \frac{6}{6} p_6\right\} = 6 p_5 = \textbf{0.006}\\
  \tilde p_1 &= \min \left\{\frac{6}{2} p_1, \frac{6}{3} p_2, 
  \frac{6}{4} p_4, \frac{6}{5} p_3, \frac{6}{6} p_6\right\} = 3 p_1 = \textbf{0.012}\\
  \tilde p_2 &= \min \left\{\frac{6}{3} p_2, 
  \frac{6}{4} p_4, \frac{6}{5} p_3, \frac{6}{6} p_6\right\} = 1.5 p_4 = \textbf{0.018}\\
  \tilde p_4 &= \min \left\{\frac{6}{4} p_4, \frac{6}{5} p_3, \frac{6}{6} p_6\right\} = 1.5 p_4 = \textbf{0.018}\\
  \tilde p_3 &= \min \left\{\frac{6}{5} p_3, \frac{6}{6} p_6\right\} = 1.2 p_3 = \textbf{0.0468}\\
  \tilde p_6 &= \frac{6}{6} p_6 = 1 p_6 = 0.480
\end{align*}
Auch diese Berechnungen können wir wieder mit Hilfe der Funktion \code{p.adjust}
kontrollieren.
<<FDR>>=
## Sortieren nicht nötig
p.adjust(pval, method = "fdr")
@
\noindent
Damit können wir die Nullhypothesen $H_{0,5}$, $H_{0,1}$, $H_{0,2}$, 
$H_{0,4}$ und auch $H_{0,3}$ zum $5\%$ Niveau ablehnen. Die adjustierten p~Werte 
sind auffallend kleiner als im Fall der FWER Methoden.
\end{Exa}
\begin{Kommentar}\noindent
Anmerkung:\\
In der Praxis kommt zur Kontrolle der FDR in den allermeisten Fällen das 
Verfahren von \citet{Benjamini1995} zum Einsatz. Ist unklar, ob die Annahme 
von positiv abhängigen Tests erfüllt ist, kann man auf die konservativere 
\textbf{Benjamini-Yekutieli-Methode} ausweichen, die in \citet{Benjamini2001} als 
Modifikation der Benjamini-Hochberg-Methode eingeführt wurde und die in jedem 
Fall die FDR kontrolliert.
\end{Kommentar}
\noindent
Im folgenden Beispiel werden wir die vorgestellten Verfahren auf einen realen 
und sehr bekannten Genexpressionsdatensatz anwenden.
\begin{Exa}
Wir verwenden die Genexpressionsdaten von \citet{Golub99}, welche im Bioconductor 
Paket \pkg{multtest} enthalten sind. Es handelt sich dabei um eine der ersten
Publikationen, in denen die Genexpression zur Vorhersage (Diagnose) einer 
Erkrankung verwendet wurde. Und zwar wurden Proben von Patienten mit akuter 
lymphastischer Leukämie (ALL) und von Patienten mit akuter myeloische Leukämie 
(AML) mittels ihrer molekularen Gensignatur klassifiziert.\\
Das Paket \pkg{multtest} enthält verschiedene Verfahren, die zur Adjustierung 
von p~Werten eingesetzt werden können. Wir laden den Datensatz \code{golub}.
<<>>=
data(golub)
str(golub)
@
\noindent
Zur Verdeutlichung wandeln wir die vorhandene Variable \code{golub.cl} in einen
Faktor um.
<<>>=
golub.cl <- factor(golub.cl, labels = c("ALL", "AML"))
table(golub.cl)
@
\noindent
Wir wenden den Welch t-Test an, um die beiden Leukämiearten zu vergleichen. 
Hierzu implementieren wir zunächst eine einfache Funktion \texttt{ttest}, die 
nur den p~Wert des Tests zurückgibt. Mit Hilfe der Funktion \code{apply} wenden
wir diese Funktion dann auf die Zeilen (\texttt{MARGIN = 1}) des Datensatzes an.
<<>>=
ttest <- function(x, g) t.test(x~g)[["p.value"]]
p.werte <- apply(X = golub, MARGIN = 1, FUN = ttest, g = golub.cl)
@
\noindent
Wir stellen die (unadjustierten) p~Werte in Form eines Histogramms graphisch 
dar.
<<>>=
hist(p.werte, nclass = 101, 
     main = "Histogram der (unadjustierten) p Werte")
@
\noindent
Das Histogramm weist mit einem deutlichen Peak bei kleinen p~Werten stark 
darauf hin, dass es viele signifikante Unterschiede zwischen den beiden 
Gruppen gibt. Um dies zu verdeutlichen, erzeugen wir im nächsten Schritt 
(Pseudo-)Zufallszahlen von zwei Gruppen, zwischen denen es keine Unterschiede 
gibt und berechnen die zugehörigen p~Werte.
<<Golub7>>=
M <- matrix(rnorm(nrow(golub)*ncol(golub)), nrow = nrow(golub))
p.werte.vgl <- apply(M, 1, ttest, g = golub.cl)
@
\noindent
Wir vergleichen die Histogramme der p~Werte der beiden Analysen miteinander.
<<>>=
par(mfrow = c(2, 1))
hist(p.werte, nclass = 101, xlab = "p Wert", main = "Golub Daten")
abline(h = 30.2)
hist(p.werte.vgl, nclass = 101, xlab = "p Wert", 
     main = "Zufallszahlen mit keinem Gruppenunterschied")
abline(h = 30.2)
@
\noindent
Im Fall, dass keine signifikanten Unterschiede vorliegen, folgen die p~Werte
des Welch t-Tests einer uniformen Verteilung (Gleichverteilung). Insbesondere
ist damit per Zufall zu erwarten, dass wir in etwa 5\% der Fälle einen p~Wert 
kleiner als 5\% -- d.h., falsch positive Testergebnisse -- erhalten. 
<<>>=
## zu erwartende Anzahl
0.05*nrow(M)
## tatsächliche Anzahl
sum(p.werte.vgl < 0.05)
@
Wir sehen, dass die erwartete Anzahl falsch positiver Tests sehr gut mit der 
tatsächlichen Anzahl übereinstimmt. Auch im Fall des realen Datensatzes, der 
die gleiche Dimension besitzt, muss man von einer entsprechenden Anzahl an 
falsch positiven Testergebnissen ausgehen. Insgesamt erhält man die folgende
Anzahl positiver Tests.
<<>>=
sum(p.werte < 0.05)
@
Wie viele dieser \Sexpr{sum(p.werte < 0.05)} positiven Testergebnisse sind
echt positiv und wie viele falsch positiv?\\
Die exakte Antwort auf diese Frage ist in der Praxis nicht bekannt. Wir berechnen
zur näherungsweisen Beantwortung dieser Frage die adjustierten p~Werte, wobei wir
die verschiedenen Methoden, die in der Funktion \code{mt.rawp2adjp} im
Paket \pkg{multtest} (\citet{multtest}) implementiert sind, anwenden.
<<>>=
p.werte.adj <- mt.rawp2adjp(p.werte)
@
\noindent
Wir berechnen für jedes der Verfahren die Anzahl der p~Werte, die kleiner als
$5\%$ sind.
<<>>=
colSums(p.werte.adj[["adjp"]] < 0.05)
@
Das erste Ergebnis stammt von den unadjustierten p~Werten. Bei den Verfahren 
\texttt{Bonferroni} bis \texttt{SidakSD} handelt es sich um Verfahren, welche
die FWER kontrollieren. Wir sehen, dass wir lediglich wenig mehr als 100 der
mehr als 1000 signifikanten Gene als echt positiv ansehen dürfen, wenn wir die 
FEWR kontrollieren wollen. In dieser Gruppe von Genen beträgt dann aber auch die
Wahrscheinlichkeit von einem oder mehr falsch positiven Tests nur maximal $5\%$.\\
Die verbleibenden vier Ergebnisse stammen von Verfahren, welche die FDR 
kontrollieren. Im Fall der Benjamini-Hochberg-Methode (\texttt{BH})
erhalten wir nahezu 700 Gene, die wir nach der Adjustierung weiterhin als 
signifikant ansehen können. Der erwartete Anteil von falsch positiven 
Testergebnissen unter diesen knapp 700 Genen beträgt demnach maximal $5\%$, 
was ungefähr $0.05\times 695\approx 35$ Genen entspricht. Bei den ursprünglichen 
1078 Genen müssen wir davon ausgehen, dass dieser Anteil bei ca.\ 
$\frac{152.55}{1078}\approx 14\%$ liegt. Anstelle von ca.\ jedem siebten positiven
Ergebnis in der unadjustierten Liste von signifikanten Genen ist in der 
reduzierten \texttt{BH}-Liste nur noch ca.\ jedes 20-zigste positive Ergebnis 
falsch positiv.\\
Interessant ist auch das Ergebnis der Benjamini-Yekutieli-Methode (\texttt{BY}), 
für welche keine zusätzliche Annahme über die Form der Abhängigkeit nötig ist.
Wir sehen, dass dieses Verfahren zwischen den FWER Methoden und dem Verfahren 
von Benjamini-Hochberg rangiert.\\
Für weitere Einzelheiten zu den nicht im Detail besprochenen Verfahren verweisen
wir auf die Hilfeseite der Funktion \code{mt.rawp2adjp} und die dort angegebene 
Literatur.
\end{Exa}
\noindent
Zum Abschluss wollen wir noch auf das Hauptergebnis der Phase I des Microarray 
Quality Control (MAQC-I) Projektes hinweisen. Ein Projekt, das von der FDA 
(U.S.\ Food and Drug Administration) initiiert wurde. In diesem Projekt, in dem 
es um die Reproduzierbarkeit der Ergebnisse von Genexpressionsanalysen mit Hilfe 
sogenannter Mikroarrays ging, zeigte sich, dass die Reproduzierbarkeit der Resultate 
erhöht werden kann, wenn man adjustierte p~Werte mit der log-fachen Veränderung 
kombiniert; siehe \citet{MAQCI}. Wir setzen das obige Beispiel fort und stellen 
diese Kombination mit Hilfe eines sogenannten \textbf{Vulkanplot (volcano plot)} 
graphisch dar.
\begin{Exa}
Für die Erzeugung des Vulkanplots müssen wir zunächst die log-fachen Veränderungen
berechnen. Wir verwenden hierzu die Funktion \code{pairwise.logfc} aus dem 
Paket \pkg{MKomics} (\citet{MKomics}).
<<>>=
logFC <- apply(golub, 1, pairwise.logfc, g = golub.cl)
@
Den Vulkanplot können wir zum Beispiel mit der Funktion \code{volcano} aus dem 
Paket \pkg{MKinfer} (\citet{MKinfer}) erzeugen. Neben der log-fachen Veränderung 
werden wir die mittels der Benjamini-Hochberg-Methode adjustierten p~Werte grafisch 
darstellen. Es ist bei Genexpressionsanalysen üblich, einen adjustierten p~Wert von 
weniger als $0.05$ als signifikant und eine Veränderung um das 2-Fache oder mehr 
als relevant einzuschätzen. Die Werte des Datensatzes sind $\log_{10}$-transformiert. 
Folglich liegt die Grenze für die log-fache Veränderung bei 
$\pm\log_{10}(2)\approx 0.3$.
<<>>=
volcano(x = logFC, pval = p.werte.adj[["adjp"]][,"BH"], effect.low = -log10(2),
        effect.high = log10(2), alpha = 0.3, 
        xlab = expression(paste(log[10], "-fache Veränderung")), 
        ylab = expression(paste(-log[10], "(adj. p Wert)")), 
        title = "Vulkanplot")
@
\noindent
Wie im Plot zu sehen ist, werden die p~Werte für die graphische
Darstellung zunächst $\log_{10}$-transformiert. Dies führt dazu, dass aus den
sehr kleinen p~Werten große negative Zahlen werden. Durch die zusätzliche Änderung
des Vorzeichens, werden aus diesen großen negativen Zahlen dann große positive 
Zahlen; d.h., die kleinen p~Werte befinden sich in der Abbildung 
oben. Die Grenze für die transformierten p~Werte liegt damit bei 
$-\log_{10}(0.05)\approx 1.3$. Die wichtigsten Gene befinden sich demnach oben 
links (blau) und oben rechts (rot) im Plot.\\
Mit Hilfe der Funktionen \code{expression} und \code{paste} lassen sich in der 
Beschriftung von Plots auch einfache mathematische Ausdrücke verwenden. Eine
genauere Beschreibung findet man auf der Hilfeseite \code{plotmath}.
\end{Exa}
\begin{Kommentar}\noindent
Anmerkung:\\
Das Ergebnis des MAQC-I Projekts ist aus statistischer Sicht nicht sehr 
überraschend, da die log-fache Veränderung in diesem Fall ein Maß für den Effekt 
ist und entsprechend auch die Relevanz der Ergebnisse repräsentiert. Unabhängig 
von Genexpressiondaten kann man davon ausgehen, dass im Fall einzelner wie auch 
multipler Tests eine Kombination aus Signifikanz und Relevanz die 
Wahrscheinlichkeit für echt positive Testergebnisse und damit auch deren 
Reproduzierbarkeit erhöht.
\end{Kommentar}
\noindent
%-------------------------------------------------------------------------------
\section{Übungsaufgaben}\label{Chap7.Ex}
%-------------------------------------------------------------------------------
Erklären Sie jeweils die Schritte Ihrer Analyse und interpretieren Sie die 
Ergebnisse. 
\begin{enumerate}
\item Adjustieren Sie die folgenden p~Werte per Hand. 
\begin{verbatim}
 0.001, 0.760, 0.550, 0.001, 0.002, 0.271, 0.005, 0.007, 0.210, 0.008
\end{verbatim}
Verwenden Sie die Methoden von 
\begin{enumerate}
\item Bonferroni
\item Bonferroni-Holm
\item Simes-Hochberg
\item Benjamini-Hochber
\end{enumerate}
Vergleichen Sie Ihre Ergebnisse mit den Ergebnissen, die Sie mit Hilfe der 
Funktion \code{p.adjust} erhalten. Interpretieren Sie die Ergebnisse der 
verschiedenen Methoden und vergleichen Sie diese miteinander.
Bestätigt sich, dass die FWER Methoden konservativer als die FDR Methode sind?
\item Führen Sie in Anlehnung an die Studie von \citet{Dodick2019} eine Fallzahlplanung
durch. Es wurden darin zwei primäre Endpunkte betrachtet. Zum einen der Anteil 
der Patienten, der nach zwei Stunden schmerzfrei ist und zum zweiten der Anteil 
der Patienten, der nach zwei Stunden frei von dem darüber hinaus lästigsten 
Symptom (Geräuschempfindlichkeit, Geruchsempfindlichkeit, Übelkeit) ist. 
Laut dem Studienprotokoll, welches unter 
\url{https://clinicaltrials.gov/ct2/show/NCT02828020} zu finden ist, waren 
die Annahmen für die Fallzahlplanung
\begin{description}
\item[Endpunkt 1:] $p_1 = 0.1$, $p_2 = 0.24$
\item[Endpunkt 2:] $p_1 = 0.267$, $p_2 = 0.377$
\end{description}
Führen Sie eine Fallzahlplanung mit Hilfe der Funktion \code{power.prop.test} 
aus dem Paket \pkg{stats} (\citet{Rcore}) durch. Die FWER soll maximal 5\% 
betragen, die Power mindestens 90\%. Sehen Sie damit die ursprünglich geplante
Fallzahl von 450 pro Gruppe als gerechtfertigt an? 
\item Laden Sie die Datei \texttt{normDaten.RData} von meinem GitHub-Account
herunter (Link: \url{https://github.com/stamats/ESDR/raw/master/normDaten.RData}).
\begin{enumerate}
\item Wenden Sie den Welch t-Test auf die Zeilen des Datensatzes \texttt{normDaten} 
an, wobei die beiden Gruppen durch den Faktor \texttt{gruppe} gegeben sind. 
Zeichnen Sie ein Histogramm der (unadjustieren) p~Werte. Erhalten Sie mehr 
signifikante Ergebnisse als per Zufall zu erwarten sind? 
\item Berechnen Sie die adjustierten p~Werte mit Hilfe der Funktion 
\texttt{mt.rawp2adjp} des Paketes \pkg{multtest} (\citet{multtest}). Vergleichen 
Sie die Ergebnisse der verschiedenen Adjustierungsverfahren, indem Sie berechnen, 
wie viele der adjustierten p~Werte jeweils kleiner als $0.05$ sind. 
\item Die Daten in \texttt{normDaten} sind $\log_2$-transformiert. Berechnen 
Sie für die Zeilen die $\log_2$-fachen Veränderungen und stellen Sie diese 
zusammen mit den Benjamini-Hochberg adjustierten p~Werten in einem Vulkanplot 
graphisch dar.
\end{enumerate}
\end{enumerate}
%-------------------------------------------------------------------------------
